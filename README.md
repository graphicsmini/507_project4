### The project option I chose : OPTION 1
### My name : Youngmin Kim


# About this program
This program is for scraping data from National Park Service website and saving the name, type, location and description of parks in each states into csv file 'npc.csv'. As you can see in requirements.txt file, you primarily need BeautifulSoup, pandas and requests to run this whole program.
You will see 'SI507_project4.py' file, which is for running the program. Also, you may see 'advanced_expiry_caching.py' which is for caching the data.


### HOW TO RUN
* Open terminal or any command prompt you have.
* Make sure you have installed all in **requirements.txt** like BeautifulSoup, pandas and requests.
* Type: python3 SI507_project4.py
* Then, you will see the cache file 'npc_cache.json' and one csv file 'npc.csv' which has all parks' information in. 